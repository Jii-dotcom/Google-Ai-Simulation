import streamlit as st
import google.generativeai as genai
import pandas as pd
from datetime import datetime
import re
from PIL import Image

# ==========================================
# 1. API í‚¤ ì„¤ì •
# ==========================================
if "GOOGLE_API_KEY" in st.secrets:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("ğŸš¨ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)

# ==========================================
# 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Lite ëª¨ë¸ìš©ìœ¼ë¡œ íƒœê·¸ ì§€ì‹œ ê°•í™”)
# ==========================================
SYSTEM_PROMPT = """
**[System Settings: Medical Simulator]**
ë„ˆëŠ” ì²¨ë¶€ëœ ì—‘ì…€ íŒŒì¼ê³¼ ë§¤ë‰´ì–¼ì„ ìˆ™ì§€í•œ ì˜ë£Œ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ì´ë‹¤.

**[Role Definition: ì ˆëŒ€ ì›ì¹™]**
1. **NO Game Master:** ë„ˆëŠ” ì§„í–‰ìê°€ ì•„ë‹ˆë‹¤. ì¡°ì–¸ì´ë‚˜ íŒíŠ¸ë¥¼ ì£¼ì§€ ë§ˆë¼.
2. **Be the Patient & Monitor:** ë„ˆëŠ” ì˜¤ì§ **í™˜ìì˜ ê³ í†µìŠ¤ëŸ¬ìš´ ë°˜ì‘**ê³¼ **ëª¨ë‹ˆí„°ì˜ ìƒì²´ì§•í›„(V/S)**ë§Œ ì¶œë ¥í•˜ë¼.
3. **Measurement Unit:** ë°©ì‚¬ì„  ì˜¤ì—¼ë„ëŠ” ë°˜ë“œì‹œ **'CPS'** ë‹¨ìœ„ë¡œ ì¶œë ¥í•˜ë¼.

**[Scenario Context: Cs-137 ìˆ˜ì†¡ì°¨ëŸ‰ ì „ë³µ]**
- ì‚¬ê³ : 14:00ê²½ ë™ìœ„ì›ì†Œ ìš´ë°˜ ì°¨ëŸ‰ ì „ë³µ.
- ì˜¤ì—¼: **ì„¸ìŠ˜ ê°€ë£¨(í°ìƒ‰)**ê°€ í™˜ìë“¤ì˜ ì˜ë³µê³¼ ì‹ ì²´ì— ë¬»ìŒ.
- ë³‘ì›: ì œì—¼ì‹¤ ì—†ìŒ. ì¼ë°˜ í™˜ì 10ëª… ë‚´ì› ì¤‘.

**[Patient Profile]**
1. **í•œê°€ì„ (ìœ„ê¸‰):** í˜¼ë¯¸, ì¶• ëŠ˜ì–´ì§, BP 80/50, HR 30, SpO2 85%. ë‚´ë¶€ì˜¤ì—¼ ì˜ì‹¬.
2. **ìµœì—¬ë¦„ (ì§€ì—°):** ëª…ë£Œ, ê·¹ë„ì˜ í¥ë¶„, ë¹„ëª… ì§€ë¦„. ë‹¤ë¦¬ ê³¨ì ˆ.

**[Logic]**
- í•œê°€ì„ì—ê²Œ ì†Œìƒìˆ  ì—†ì´ ì œì—¼ ë¨¼ì € ì‹œë„ ì‹œ ìƒíƒœ ê¸‰ê²© ì•…í™”.
- ìµœì—¬ë¦„ì—ê²Œ 3í„´ ì´ìƒ ì •ì‹  íŒ”ë¦¬ë©´ í•œê°€ì„ ì‚¬ë§.

**[â˜…â˜…â˜… Visual Output Protocol: ì¤‘ìš” â˜…â˜…â˜…]**
ë„ˆëŠ” ë‹µë³€ì„ ë§ˆì¹  ë•Œë§ˆë‹¤ **ë°˜ë“œì‹œ** í˜„ì¬ ìƒí™©ì„ ë¬˜ì‚¬í•˜ëŠ” ì´ë¯¸ì§€ ìƒì„± ì½”ë“œë¥¼ ë§ˆì§€ë§‰ ì¤„ì— ì¶”ê°€í•´ì•¼ í•œë‹¤.
í˜•ì‹: `<<<IMAGE_PROMPT: (ì˜ì–´ ìƒí™© ë¬˜ì‚¬)>>>`

* (ì˜ˆì‹œ 1 - ì‹œì‘ ì‹œ): `<<<IMAGE_PROMPT: An overturned truck on a highway, white dust covering injured patients, realistic photo style.>>>`
* (ì˜ˆì‹œ 2 - ìœ„ë…): `<<<IMAGE_PROMPT: A medical monitor showing flatline Asystole, red alarm lights flashing, dark atmosphere.>>>`
* (ì˜ˆì‹œ 3 - ì¼ë°˜ ì§„ë£Œ): `<<<IMAGE_PROMPT: A doctor checking patient's eyes with a flashlight, first person view, realistic medical drama style.>>>`

**[Start Protocol]**
ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ì‹œ ì˜¤í”„ë‹ì„ ì—´ì–´ë¼:
"ğŸš¨ **ìƒí™© ë°œìƒ! Cs-137 ìš´ë°˜ ì°¨ëŸ‰ ì „ë³µ ì‚¬ê³ !**
í™˜ìë“¤ì˜ ì˜·ì— **í•˜ì–€ ê°€ë£¨(ì„¸ìŠ˜ ì˜ì‹¬)**ê°€ ì”ëœ© ë¬»ì–´ìˆìŠµë‹ˆë‹¤!
**(ì¹¨ëŒ€ 1) í•œê°€ì„:** ì¶• ëŠ˜ì–´ì ¸ ìˆê³  ì•ˆìƒ‰ì´ ì°½ë°±í•©ë‹ˆë‹¤. (ì‚... ì‚...)
**(ì¹¨ëŒ€ 2) ìµœì—¬ë¦„:** ë‹¤ë¦¬ë¥¼ ë¶™ì¡ê³  ë¹„ëª…ì„ ì§€ë¦…ë‹ˆë‹¤. 'ì•„ì•…! ë‚˜ë¶€í„° ì‚´ë ¤ì¤˜ìš”!!'
**íŒ€ì¥ë‹˜, ëˆ„êµ¬ë¶€í„° ì§„ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?**"
<<<IMAGE_PROMPT: An overturned transport truck carrying radioactive materials on a highway, with two injured patients lying on stretchers covered in white dust, emergency personnel responding, realistic photo style.>>>
"""

# ==========================================
# 3. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (ì—¬ê¸°ëŠ” Imagen ëª¨ë¸ ì‚¬ìš© í•„ìˆ˜)
# ==========================================
def generate_image(prompt):
    """Imagen ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # í…ìŠ¤íŠ¸ ëª¨ë¸ì€ Flash-liteë¥¼ ì“°ë”ë¼ë„, ê·¸ë¦¼ì€ í™”ê°€(Imagen)ê°€ ê·¸ë ¤ì•¼ í•©ë‹ˆë‹¤.
        imagen_model = genai.ImageGenerationModel("imagen-4.0-generate-001")
        result = imagen_model.generate_images(
            prompt=prompt, number_of_images=1, aspect_ratio="16:9", safety_filter_level="block_some"
        )
        return result.images[0]
    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë©´ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤ (ë””ë²„ê¹…ìš©)
        st.warning(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤): {e}") 
        return None

# ==========================================
# 4. í™”ë©´ êµ¬ì„± ë° ì‚¬ì´ë“œë°”
# ==========================================
st.set_page_config(page_title="ë°©ì‚¬ì„  ë¹„ìƒì§„ë£Œ ì‹œë®¬ë ˆì´í„°", page_icon="â˜¢ï¸", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "api_history" not in st.session_state:
    st.session_state.api_history = []
if "evaluation" not in st.session_state:
    st.session_state.evaluation = None

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("ğŸ‘¤ êµìœ¡ìƒ ì •ë³´")
    trainee_name = st.text_input("ì´ë¦„", placeholder="ì˜ˆ: í™ê¸¸ë™")
    trainee_id = st.text_input("ì†Œì†", placeholder="ì˜ˆ: ì›ìë ¥ë³‘ì›")
    
    st.markdown("---")
    st.header("ğŸ“‹ ì»¨íŠ¸ë¡¤ íŒ¨ë„")
    if st.button("ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ì´ˆê¸°í™” (Reset)"):
        st.session_state.chat_history = []
        st.session_state.api_history = []
        st.session_state.evaluation = None
        st.rerun()

# ==========================================
# 5. ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
# ==========================================
st.title("â˜¢ï¸ ë°©ì‚¬ì„  ë¹„ìƒì§„ë£Œ ì‹œë®¬ë ˆì´í„°")
st.caption(f"Trauma & Radiation Response Training System | Model: gemini-flash-lite-latest")

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        if msg["type"] == "text":
            st.write(msg["content"])
        elif msg["type"] == "image":
            st.image(msg["content"], caption="í˜„ì¥ ì‹œê°í™”", use_column_width=True)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if st.session_state.evaluation is None:
    if user_input := st.chat_input("ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘)"):
        # 1. ì‚¬ìš©ì ì…ë ¥ í‘œì‹œ
        with st.chat_message("user"):
            st.write(user_input)
        
        st.session_state.chat_history.append({"role": "user", "type": "text", "content": user_input})
        st.session_state.api_history.append({"role": "user", "parts": [user_input]})
        
        # 2. AI ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            with st.spinner("ìƒí™© íŒë‹¨ ë° ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
                try:
                    # ìš”ì²­í•˜ì‹  [gemini-flash-lite-latest] ëª¨ë¸ ì‚¬ìš©
                    # ë§Œì•½ ì´ ëª¨ë¸ëª…ì´ API ì˜¤ë¥˜ê°€ ë‚˜ë©´ 'gemini-1.5-flash'ë¡œ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.
                    chat_model = genai.GenerativeModel(
                        model_name="gemini-flash-lite-latest", 
                        system_instruction=SYSTEM_PROMPT
                    )
                    
                    chat = chat_model.start_chat(history=st.session_state.api_history)
                    response = chat.send_message(user_input)
                    response_text = response.text

                    # ì´ë¯¸ì§€ íƒœê·¸ ê°ì§€ (<<<IMAGE_PROMPT: ... >>>)
                    image_match = re.search(r"<<<IMAGE_PROMPT:(.*?)>>>", response_text, re.DOTALL)
                    
                    final_text_to_display = response_text
                    generated_image = None

                    if image_match:
                        img_prompt = image_match.group(1).strip()
                        # í…ìŠ¤íŠ¸ì—ì„œ íƒœê·¸ ì œê±° (í™”ë©´ì—” ì•ˆ ë³´ì´ê²Œ)
                        final_text_to_display = response_text.replace(image_match.group(0), "")
                        
                        # ì´ë¯¸ì§€ ìƒì„± ì‹œë„
                        generated_image = generate_image(img_prompt)
                    else:
                        # íƒœê·¸ê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œë¼ë„ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì§€, ì•„ë‹ˆë©´ ë„˜ì–´ê°ˆì§€ ê²°ì •
                        # Lite ëª¨ë¸ì´ íƒœê·¸ë¥¼ ë¹¼ë¨¹ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¡œê·¸ë§Œ ì¶œë ¥
                        print("AIê°€ ì´ë¯¸ì§€ íƒœê·¸ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                    # 3. ê²°ê³¼ ì¶œë ¥
                    if final_text_to_display.strip():
                        st.write(final_text_to_display)
                        st.session_state.chat_history.append({"role": "assistant", "type": "text", "content": final_text_to_display})
                        st.session_state.api_history.append({"role": "model", "parts": [final_text_to_display]})
                    
                    if generated_image:
                        st.image(generated_image, caption="AI í˜„ì¥ ì¬í˜„ ì´ë¯¸ì§€", use_column_width=True)
                        st.session_state.chat_history.append({"role": "assistant", "type": "image", "content": generated_image})

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.info("íŒ: ëª¨ë¸ëª… ì˜¤ë¥˜ë¼ë©´ 'gemini-1.5-flash'ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”.")

# ==========================================
# 6. í‰ê°€ ë° ë°ì´í„° ì œì¶œ
# ==========================================
st.markdown("---")
if st.session_state.evaluation is None:
    st.subheader("ğŸ“Š í›ˆë ¨ ì¢…ë£Œ ë° í‰ê°€")
    
    if st.button("í›ˆë ¨ ì¢…ë£Œ ë° í‰ê°€ ë°›ê¸°"):
        if not trainee_name or not trainee_id:
            st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ì´ë¦„'ê³¼ 'ì†Œì†'ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            if len(st.session_state.api_history) < 2:
                st.warning("âš ï¸ ëŒ€í™” ê¸°ë¡ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("í‰ê°€ ë¶„ì„ ì¤‘..."):
                    try:
                        # í‰ê°€ ëª¨ë¸ë„ ìš”ì²­í•˜ì‹  ëª¨ë¸ë¡œ í†µì¼
                        eval_model = genai.GenerativeModel("gemini-flash-lite-latest")
                        full_log = "\n".join([f"{msg['role']}: {msg['parts'][0]}" for msg in st.session_state.api_history])
                        
                        eval_prompt = f"""
                        ë„ˆëŠ” í‰ê°€ê´€ì´ë‹¤. ì•„ë˜ ë¡œê·¸ë¥¼ ë¶„ì„í•´ë¼.
                        [ë¡œê·¸] {full_log}
                        [í˜•ì‹]
                        1. ìƒì¡´ ì—¬ë¶€:
                        2. ì£¼ìš” ì²˜ì¹˜:
                        3. ì˜í•œ ì :
                        4. ê°œì„ í•  ì :
                        5. ì ìˆ˜(100ì  ë§Œì ):
                        """
                        eval_response = eval_model.generate_content(eval_prompt)
                        st.session_state.evaluation = eval_response.text
                        st.rerun()
                    except Exception as e:
                        st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")

if st.session_state.evaluation:
    st.success("âœ… í‰ê°€ ì™„ë£Œ!")
    st.info(st.session_state.evaluation)
    
    full_conversation = "\n".join([f"[{msg['role']}] {msg['parts'][0]}" for msg in st.session_state.api_history])
    data = {
        "ì´ë¦„": [trainee_name], "ì†Œì†": [trainee_id],
        "ë‚ ì§œ": [datetime.now().strftime("%Y-%m-%d")],
        "í‰ê°€ê²°ê³¼": [st.session_state.evaluation], "ëŒ€í™”ë¡œê·¸": [full_conversation]
    }
    df = pd.DataFrame(data)
    csv = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)", data=csv, file_name="result.csv", mime="text/csv")

